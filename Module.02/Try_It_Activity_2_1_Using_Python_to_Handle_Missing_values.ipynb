{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvmsbE77nXYM"
   },
   "source": [
    "# Self-study try-it activity 2.1: Using Python to handle missing values\n",
    "\n",
    "In data analysis, missing values can be both obstacles to insight and clues to deeper patterns. Like detectives piecing together evidence, data scientists must explore data sets to identify, understand and strategically address these gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOfEmP0XoIWt"
   },
   "source": [
    "## 1. Detecting missing values\n",
    "\n",
    "The first step in handling missing values is to detect them. Let’s explore different methods for identifying missing values in `arrays`, `series` and `DataFrames`. \n",
    "\n",
    "- Boolean masking of missing values using Pandas\n",
    "\n",
    "- Counting missing values\n",
    "\n",
    "- Visualising missing data\n",
    "\n",
    "- Checking missing values in `arrays`\n",
    "\n",
    "- Detecting missing values in `series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBkUwMVgp4dU"
   },
   "source": [
    "Let's explore the first method.\n",
    "\n",
    "### a. Boolean masking of missing values using `Pandas`.\n",
    "\n",
    "The methods `isnull()` and `notnull()` are used to create Boolean masks for missing values. `isnull()` returns `True` for missing values and `False` otherwise, while `notnull()` does the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdM3zuiRmx0p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4], 'B': [None, 2, 3, None]})\n",
    "\n",
    "#Detect missing values using isnull() and notnull()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGg9PPcNqxI2"
   },
   "source": [
    "### b. Counting missing values\n",
    "\n",
    "The missing values in a data set are counted using the `.sum()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apV4GiF3qvgy"
   },
   "outputs": [],
   "source": [
    "missing_count = None\n",
    "\n",
    "#Compute the missing count\n",
    "print(missing_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtNN9RHZrUzp"
   },
   "source": [
    "### c. Visualising missing data\n",
    "\n",
    "Seaborn is a Python library built on top of Matplotlib, designed to simplify the creation of visually appealing and informative statistical graphics. It integrates seamlessly with pandas `DataFrames`to support data analysis and visualisation.\n",
    "\n",
    "One useful plot type is the heatmap, a graphical representation in which individual values are displayed as colour gradients. Heatmaps are especially helpful for visualising missing data, correlations or any matrix-like data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMRafTtorFmk"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(df.isnull())\n",
    "plt.show()\n",
    "#Display the heatmap with cbar=True, cmap=\"viridis\". What change do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPJZn_BqQig1"
   },
   "source": [
    "### d. Checking missing values in `arrays`\n",
    "\n",
    "Use NumPy’s `isnan()` function to detect missing values in `arrays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_pDQCmDQSK7"
   },
   "outputs": [],
   "source": [
    "#Declare an array with missing values and display the presence of null values in the array\n",
    "array = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZU6oIiPRb3d"
   },
   "source": [
    "### e. Detecting missing values in `series`\n",
    "\n",
    "Use pandas' `isna()` function to detect `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY5YEmueQzCS"
   },
   "outputs": [],
   "source": [
    "series = None\n",
    "series = pd.Series([1, None, 3, np.nan])\n",
    "\n",
    "#Display the missing values in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X97-7T88T_2S"
   },
   "source": [
    "## 2. Removing missing values\n",
    "\n",
    "After detecting missing values in Python, one common approach is to remove them, especially when the missing data is minimal or when it cannot be reasonably imputed. \n",
    "\n",
    "The different ways of removal rows and/or column(s) with missing values are:\n",
    "\n",
    "- Removing rows with missing values\n",
    "\n",
    "- Removing columns with missing values\n",
    "\n",
    "- Removing rows or columns based on a threshold\n",
    "\n",
    "- Removing rows where all values are missing\n",
    "\n",
    "- Removing columns where all values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2i7993dRSx6B"
   },
   "outputs": [],
   "source": [
    "#Removing rows with missing values\n",
    "#When df.dropna() is used, it removes rows in which any column has a missing value.\n",
    "data = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8], 'C': [9, 10, 11, np.nan]}\n",
    "df = pd.DataFrame(data)\n",
    "df_cleaned =None\n",
    "\n",
    "#Explain why df.dropna() returns only one row (index 0) for this data set.\n",
    "#How would the outcome change if only one row had no missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiuKx-GBVuoi"
   },
   "outputs": [],
   "source": [
    "#Removing columns with missing values\n",
    "#If entire columns contain many missing values, they can be dropped using dropna(axis=1).\n",
    "df_cleaned_columns = None\n",
    "\n",
    "#Explain why df.dropna(axis=1) results in a DataFrame with no columns for the given data set.\n",
    "#How would the outcome change if one column had no missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1y6W0fdDW2RG"
   },
   "outputs": [],
   "source": [
    "#Removing rows/columns based on threshold\n",
    "#The threshold for the minimum number of non-missing values required in a row or column can be specified using the `thresh` parameter.\n",
    "df_cleaned_threshold = None\n",
    "df_cleaned_threshold = df.dropna(thresh=2)\n",
    "print(df_cleaned_threshold)\n",
    "#Comment on what happens when `thresh=3`. Give your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "moYHkxwrXWIT"
   },
   "outputs": [],
   "source": [
    "#Removing rows where all values are missing\n",
    "#To remove rows where all columns are missing, use how='all'\n",
    "df_cleaned_all = None\n",
    "\n",
    "#Explain the difference between using how='any' and how='all' in dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cftvkLdEYT5T"
   },
   "outputs": [],
   "source": [
    "#Removing columns where all values are missing\n",
    "# Columns where all entries are missing can be dropped by setting axis=1 and how='all'\n",
    "df_all_nan_columns_removed = None\n",
    "\n",
    "#Explain the scenarios in which you would use dropna(axis=1, how='all') to remove columns\n",
    "#Provide examples of when this approach is beneficial for data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPiVwuXzlAfS"
   },
   "source": [
    "## 3. Imputing missing values\n",
    "\n",
    "Imputing missing values involves replacing `NaN` or missing entries in a data set with appropriate values to ensure the data set remains usable for analysis or modelling. Imputing can be performed in a variety of ways, such as:\n",
    "\n",
    "- Imputing with the mean or the median\n",
    "\n",
    "- Imputing with the mode\n",
    "\n",
    "- Imputing with the constant value\n",
    "\n",
    "- Imputing with `SimpleImputer`\n",
    "\n",
    "- Predictive imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gu2EbhBI1m3S"
   },
   "source": [
    "### a. Imputing with the mean or the median\n",
    "\n",
    "Imputing with the mean is a common technique for numerical data, where the mean of the column replaces missing values. This approach is suitable when the proportion of missing data is small and the mean does not significantly distort the overall distribution.\n",
    "\n",
    "Imputing with the median is a better choice when the data contains outliers that could skew the mean, as the median is less sensitive to extreme values and provides a more robust estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRWnnMCrjKRS"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8], 'C':[156,200,np.nan,5]})\n",
    "df_imputed_mean = None\n",
    "df_imputed_median = None\n",
    "\n",
    "#Compare the results of using mean() and median() for imputation. How do the imputed values differ, and what might cause these differences?\n",
    "#With the addition of column 'C' containing values [156, 200, np.nan, 5],\n",
    "#Explain why you would prefer to use either mean() or median() for imputation. Consider the impact of outliers on your choice.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IMT2vru6BPI"
   },
   "source": [
    "### b. Imputing with the mode\n",
    "\n",
    "You can use the mode to impute the missing values for categorical data, when the missing values are replaced with the mode (the most frequent value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-awiqIb5_WJ"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Category': ['A', 'B', np.nan, 'A', 'C', np.nan]})\n",
    "\n",
    "# Impute missing values with mode\n",
    "df_new = None\n",
    "\n",
    "#Compare the count of 'A' in the original DataFrame and in df_new\n",
    "#How does imputing missing values with the mode affect the frequency of 'A'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6CUzBo48S53"
   },
   "source": [
    "### c. Imputing with the constant value\n",
    "\n",
    "Use this method when you want to assign a default value to indicate the missing data explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-iPDt9q7O_0"
   },
   "outputs": [],
   "source": [
    "# Replace NaN in numerical column with a constant value (e.g. -1)\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8]})\n",
    "#df_constant = None\n",
    "\n",
    "#What happens when you replace missing values (NaN) in a numerical column with a constant value like 10?\n",
    "#Compare the original DataFrame and the resulting DataFrame after imputation\n",
    "#How might this approach affect subsequent data analysis or modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NsHBS4H-i9s"
   },
   "source": [
    "### d. Imputing with `SimpleImputer`\n",
    "\n",
    "`SimpleImputer` is a class in the `scikit-learn` library used to handle missing values in data sets by replacing them with specific imputed values. It provides a systematic way to fill in missing data using strategies like mean, median, most frequent value (mode) or constant value. It works seamlessly with machine learning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a_LrTE79Wuz"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'Age': [25, 30, np.nan, 35], 'Salary': [50000, np.nan, 60000, 65000]})\n",
    "\n",
    "#Instantiate SimpleImputer with strategy='mean'\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "#Apply imputation\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame After Imputation:\")\n",
    "print(df_imputed)\n",
    "#Use strategy='median' and compare the difference between the mean imputer and median imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecuXp1bv_wrU"
   },
   "source": [
    "### e. Predictive imputation\n",
    "\n",
    "Predictive imputation is a common technique for handling missing data in large data sets. Using machine learning models to estimate missing values based on feature relationships ensures data integrity and improves downstream analysis accuracy. However, it requires careful model selection and computational resources to handle large-scale data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKYyXeWi_aY2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Create a DataFrame with missing values\n",
    "df = pd.DataFrame({\n",
    "    'Age': [25, 30, np.nan, 35],\n",
    "    'Salary': [50000, np.nan, 60000, 65000],\n",
    "    'Experience': [2, 5, 7, np.nan]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "#Separate rows with and without missing values for the 'Salary' column\n",
    "train_data = df[df['Salary'].notnull()]\n",
    "test_data = df[df['Salary'].isnull()]\n",
    "\n",
    "#Train a regression model to predict 'Salary' based on other columns\n",
    "model = LinearRegression()\n",
    "X_train = train_data[['Age', 'Experience']].fillna(0)  # Fill NaNs in predictors temporarily\n",
    "y_train = train_data['Salary']\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict missing 'Salary' values\n",
    "X_test = test_data[['Age', 'Experience']].fillna(0)\n",
    "predicted_salary = model.predict(X_test)\n",
    "\n",
    "#Impute the predicted values into the original DataFrame\n",
    "df.loc[df['Salary'].isnull(), 'Salary'] = predicted_salary\n",
    "\n",
    "print(\"\\nDataFrame After Predictive Imputation:\")\n",
    "print(df)\n",
    "#Modify the code to use predictive imputation for imputing missing values in the Age column.\n",
    "#Use Salary and Experience as predictors.\n",
    "#Compare the results with the original imputation of Salary."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
