{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook 1.2: Applying calculus in Python\n",
    "\n",
    "Calculus provides essential tools for understanding and optimising functions. The derivative measures the rate of change of a function with respect to a single variable, helping to identify maxima, minima and points of inflection. For functions of multiple variables, partial differentiation calculates the derivative with respect to one variable while keeping the others constant, enabling the analysis of complex systems.\n",
    "\n",
    "The norm quantifies the size or length of a vector and is often used to measure distances or magnitudes in multidimensional spaces.\n",
    "\n",
    "Based on these concepts, gradient descent is an iterative optimisation algorithm that uses the gradient (a vector of partial derivatives) to move towards a function’s minimum by stepping in the direction of steepest descent. It is widely used in ML and numerical optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEqXaZLShmQA"
   },
   "source": [
    "## 1. Derivatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iY4HgTHChdJY",
    "outputId": "87008795-00e7-47ce-be14-9ad837dd5d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of x^7: 15*x**2 - 8*x + 6\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, diff\n",
    "\n",
    "x = symbols('x')\n",
    "f = 5 * x**3 - 4 * x**2 + 6 * x - 7 # Function\n",
    "f_derivative = diff(f, x)\n",
    "print(\"Derivative of x^7:\", f_derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3-_jp2Yhq7w"
   },
   "source": [
    "## 2. Partial derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRZxT5aohvLE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial derivative with respect to x: 2*x + 4*y\n",
      "Partial derivative with respect to y: 4*x\n",
      "Partial derivative with respect to z: 0\n",
      "\n",
      "Evaluating partial derivatives at x=1, y=2, z=3:\n",
      "Partial derivative with respect to x: 10\n",
      "Partial derivative with respect to y: 4\n",
      "Partial derivative with respect to z: 0\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, sin, diff\n",
    "\n",
    "# Define the variables\n",
    "# x, y, z = symbols('x y z')\n",
    "x, y = symbols('x y')\n",
    "\n",
    "# Define the function\n",
    "# f = 4*x*y + x*sin(z) + x**3 + z**8*y\n",
    "f = 4*x*y + x**2\n",
    "\n",
    "# Calculate the partial derivatives\n",
    "f_partial_x = diff(f, x)\n",
    "f_partial_y = diff(f, y)\n",
    "f_partial_z = diff(f, z)\n",
    "\n",
    "# Print the partial derivatives\n",
    "print(\"Partial derivative with respect to x:\", f_partial_x)\n",
    "print(\"Partial derivative with respect to y:\", f_partial_y)\n",
    "# print(\"Partial derivative with respect to z:\", f_partial_z)\n",
    "\n",
    "# Evaluate the partial derivatives at specific points\n",
    "# For example, evaluate at x=1, y=2, z=3\n",
    "'''\n",
    "print(\"\\nEvaluating partial derivatives at x=1, y=2, z=3:\")\n",
    "print(\"Partial derivative with respect to x:\", f_partial_x.subs({x: 1, y: 2, z: 3}))\n",
    "print(\"Partial derivative with respect to y:\", f_partial_y.subs({x: 1, y: 2, z: 3}))\n",
    "print(\"Partial derivative with respect to z:\", f_partial_z.subs({x: 1, y: 2, z: 3}))\n",
    "''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pbCkqGEh4Ac"
   },
   "source": [
    "## 3. Chain rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZykvAzhoh9ck",
    "outputId": "7462f74e-be6d-4520-df18-b8c742f38917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative using Chain Rule: 6*x*(x**2 + 1)**2\n"
     ]
    }
   ],
   "source": [
    "g = (x**2 + 1)**3\n",
    "g_derivative = diff(g, x)\n",
    "print(\"Derivative using Chain Rule:\", g_derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSsOgMFAo2o-"
   },
   "source": [
    "## 4. Norms\n",
    "\n",
    "In mathematics, a norm is a way to measure the size or length of a vector. Think of it like measuring how far a point is from the origin (0, 0) in a graph. Norms are important because they help you understand how big or small a vector is, which is crucial in many mathematical and computational applications.\n",
    "\n",
    "### Common types of norms:\n",
    "\n",
    "- **L1 norm (Manhattan distance)**: sums the values of all elements in a vector\n",
    "\n",
    "- **L2 norm (Euclidean distance)**: takes the square root of the sum of the squares of all elements\n",
    "\n",
    "- **L∞ norm (max norm)**: the maximum absolute value among all elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUfLw_rTpXbt"
   },
   "source": [
    "The `NumPy` library uses the function `.linalg.norm()` to calculate the norm (magnitude or length) of a vector:\n",
    "\n",
    "- The `ord=1` indicates that it is an L1-norm.\n",
    "\n",
    "- The default is an L2-norm. \n",
    "\n",
    "- For L∞ norms, the `ord` is `ord=np.inf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oS7ABsKzo4jo",
    "outputId": "c4be4af3-8330-485c-931a-6487d3dd5beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm: 6.0\n",
      "L2 Norm: 3.7416573867739413\n",
      "L∞ Norm: 3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a vector\n",
    "vector = np.array([1, 2, 3])\n",
    "\n",
    "# Calculate the L1 norm\n",
    "l1_norm = np.linalg.norm(vector, ord=1)\n",
    "print(f\"L1 Norm: {l1_norm}\")\n",
    "\n",
    "# Calculate the L2 norm (default)\n",
    "l2_norm = np.linalg.norm(vector)\n",
    "print(f\"L2 Norm: {l2_norm}\")\n",
    "\n",
    "# Calculate the L∞ norm\n",
    "inf_norm = np.linalg.norm(vector, ord=np.inf)\n",
    "print(f\"L∞ Norm: {inf_norm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPAOnh6xvARR"
   },
   "source": [
    "## 5. Gradient descent\n",
    "\n",
    "In this practice exercise, you will apply gradient descent to minimise the function `f(x)=(x−3)2`, which has its minimum at `x = 3`.\n",
    "\n",
    "The gradient of the function is `f′(x) = 2(x − 3)`, and the value of `x` is updated by moving in the direction opposite to the gradient. In this case, the learning rate (`α`) is set to 0.1.\n",
    "\n",
    "You can vary the number of iterations to observe how `x` converges towards the minimum.\n",
    "\n",
    "The updated values of `x` after each iteration will be stored in a history list, allowing you to track how `x` changes over time.\n",
    "\n",
    "Feel free to experiment with the number of iterations and the learning rate to explore their effects on the convergence rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IC2GctlQoIMF",
    "outputId": "694636a5-56d0-47dc-981b-67f9cae5ab22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 8.6, 7.4799999999999995, 6.584]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given function: f(x) = (x - 3)^2\n",
    "# Derivative: f'(x) = 2(x - 3)\n",
    "# Initial value: x0 = 10\n",
    "# Learning rate: alpha = 0.1\n",
    "# Perform three iterations\n",
    "# You can vary the number of iterations to analyse the convergence\n",
    "# Initialisation\n",
    "x = 10  # initial guess\n",
    "alpha = 0.1  # learning rate\n",
    "iterations = 3  # number of iterations\n",
    "# Perform gradient descent updates\n",
    "history = [x]\n",
    "for _ in range(iterations):\n",
    "    gradient = 2 * (x - 3)  # Compute the derivative f'(x)\n",
    "    x = x - alpha * gradient  # Update x\n",
    "    history.append(x)\n",
    "history\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "appenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
